{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size = 5 color = black>Custom Dataset </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x(path, width):\n",
    "    \"\"\"Gets the x value from the image filename\"\"\"\n",
    "    return (float(int(path.split(\"_\")[1])) - width/2) / (width/2)\n",
    "\n",
    "def get_y(path, height):\n",
    "    \"\"\"Gets the y value from the image filename\"\"\"\n",
    "    return (float(int(path.split(\"_\")[2])) - height/2) / (height/2)\n",
    "\n",
    "class XYDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, directory, random_hflips=False):\n",
    "        self.directory = directory\n",
    "        self.random_hflips = random_hflips\n",
    "        \n",
    "        self.image_paths = glob.glob(os.path.join(self.directory, 'block', '*.jpg')) + glob.glob(os.path.join(self.directory, 'free', '*.jpg'))\n",
    "\n",
    "        \n",
    "        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "   \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if \"block\" in self.image_paths[idx]:\n",
    "            label = 0.0\n",
    "        if \"free\" in self.image_paths[idx]:\n",
    "            label = 1.0\n",
    "        \n",
    "        image = PIL.Image.open(self.image_paths[idx])\n",
    "        width, height = image.size\n",
    "        x = float(get_x(os.path.basename(self.image_paths[idx]), width))\n",
    "        y = float(get_y(os.path.basename(self.image_paths[idx]), height))\n",
    "      \n",
    "        if float(np.random.rand(1)) > 0.5:\n",
    "            image = transforms.functional.hflip(image)\n",
    "            x = -x\n",
    "        \n",
    "        image = self.color_jitter(image)\n",
    "        image = transforms.functional.resize(image, (224, 224))\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = image.numpy()[::-1].copy()\n",
    "        image = torch.from_numpy(image)\n",
    "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        # Regression, Classification\n",
    "        return image, torch.tensor([x, y]).float(), label\n",
    "\n",
    "    \n",
    "dataset = XYDataset('dataset_merge_v3', random_hflips=False)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size = 5 color black>Set train set and test set</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size = 5 color = black>報錯修正</font>**\n",
    "\n",
    "<font color = blue>如果無法執行模型，並發現是報錯在loss.backward()的話\n",
    "<br>清除dataset(包含)資料夾內部的資料夾的ipynb_checkpoints\n",
    "<br>清除方式:\n",
    "<br><font color = red>du -chd 1 | sort -h 進行查詢</font>\n",
    "<br><font color = red>rm -rf .ipynb_checkpoints 進行清除</font>\n",
    "<br><font color = blue>驗證，觀察train_dataset, test_dataset的總和是否為正確數值</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_percent = 0.4\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = blue size = 6> Test data label value</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super( MultiOutputModel, self).__init__()\n",
    "        self.out1 = torch.nn.Linear(512, 2)\n",
    "        self.out2 = torch.nn.Linear(512, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_out1 = self.out1(x)\n",
    "        x_out2 = self.out2(x) \n",
    "        return x_out1, x_out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = MultiOutputModel()\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "\n",
    "NUM_EPOCHS = 60\n",
    "# NUM_EPOCHS = 30\n",
    "BEST_MODEL_PATH = 'Merge_Function_Robot_final_v13.pth'\n",
    "best_loss = 1e9\n",
    "best_accuracy = 0.0\n",
    "\n",
    "#Regression & Classification\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for images, label_regression, label_classification in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "  \n",
    "        label_regression = label_regression.to(device)  \n",
    "        label_classification = label_classification.long().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        \n",
    "        output1, output2 = model(images)   \n",
    "        #Regression\n",
    "        loss1 = F.mse_loss(output1, label_regression)\n",
    "        #Classification\n",
    "        loss2 = F.cross_entropy(output2, label_classification)\n",
    "        \n",
    "        train_loss += float(loss1)     \n",
    "        loss_total = loss1 + loss2\n",
    "        loss_total.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "     \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_error_count = 0.0\n",
    "    \n",
    "    for images, label_regression, label_classification in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        label_regression = label_regression.to(device) \n",
    "        label_classification = label_classification.long().to(device) \n",
    "        \n",
    "        output1, output2 = model(images)   \n",
    "        \n",
    "        # Regression\n",
    "        loss = F.mse_loss(output1, label_regression)\n",
    "        test_loss += float(loss)  \n",
    "        #Classification\n",
    "        test_error_count += float(torch.sum(torch.abs(label_classification - output2.argmax(1))))\n",
    "        \n",
    "    #Regression\n",
    "    test_loss /= len(test_loader)\n",
    "    #Classification\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n",
    "    \n",
    "    print('%d: %f' % (epoch, test_accuracy))\n",
    "    print('%f, %f' % (train_loss, test_loss))\n",
    "    \n",
    "    if (test_loss < best_loss) or (test_accuracy > best_accuracy):\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        if (test_loss < best_loss):\n",
    "            best_loss = test_loss\n",
    "        if (test_accuracy > best_accuracy):\n",
    "            best_accuracy = test_accuracy\n",
    "end = time.time()\n",
    "print(\"finish\")    \n",
    "second = (end - start)\n",
    "\n",
    "minute = second // 60\n",
    "hour = second // 60 //60\n",
    "second = second % 60 % 60\n",
    "print('this model training spends %0dhr %0dmin %0ds' % (hour, minute, second))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
