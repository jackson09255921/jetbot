{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import glob\n",
    "import PIL.Image\n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# a = glob.glob(os.path.join('dataset_merge', 'block', '*.jpg'))\n",
    "# b = glob.glob(os.path.join('dataset_merge', 'free', '*.jpg'))\n",
    "# c = os.path.basename(os.path.dirname(a[0]))\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size = 5 color = black>Custom Dataset </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.XYDataset object at 0x7f7c0bbef0>\n"
     ]
    }
   ],
   "source": [
    "def get_x(path, width):\n",
    "    \"\"\"Gets the x value from the image filename\"\"\"\n",
    "    return (float(int(path.split(\"_\")[1])) - width/2) / (width/2)\n",
    "\n",
    "def get_y(path, height):\n",
    "    \"\"\"Gets the y value from the image filename\"\"\"\n",
    "    return (float(int(path.split(\"_\")[2])) - height/2) / (height/2)\n",
    "\n",
    "class XYDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, directory, random_hflips=False):\n",
    "        self.directory = directory\n",
    "        self.random_hflips = random_hflips\n",
    "        \n",
    "        self.image_paths = glob.glob(os.path.join(self.directory, 'block', '*.jpg')) + glob.glob(os.path.join(self.directory, 'free', '*.jpg'))\n",
    "\n",
    "        \n",
    "        self.color_jitter = transforms.ColorJitter(0.3, 0.3, 0.3, 0.3)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "   \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if \"block\" in self.image_paths[idx]:\n",
    "            label = 0.0\n",
    "        if \"free\" in self.image_paths[idx]:\n",
    "            label = 1.0\n",
    "        \n",
    "        image = PIL.Image.open(self.image_paths[idx])\n",
    "        width, height = image.size\n",
    "        x = float(get_x(os.path.basename(self.image_paths[idx]), width))\n",
    "        y = float(get_y(os.path.basename(self.image_paths[idx]), height))\n",
    "      \n",
    "        if float(np.random.rand(1)) > 0.5:\n",
    "            image = transforms.functional.hflip(image)\n",
    "            x = -x\n",
    "        \n",
    "        image = self.color_jitter(image)\n",
    "        image = transforms.functional.resize(image, (224, 224))\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        image = image.numpy()[::-1].copy()\n",
    "        image = torch.from_numpy(image)\n",
    "        image = transforms.functional.normalize(image, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        \n",
    "        # Regression, Classification\n",
    "        return image, torch.tensor([x, y]).float(), label\n",
    "\n",
    "    \n",
    "dataset = XYDataset('dataset_merge_v3', random_hflips=False)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size = 5 color black>Set train set and test set</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = datasets.ImageFolder(\n",
    "#     'dataset_merge',\n",
    "#     transforms.Compose([\n",
    "#         transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),\n",
    "#         transforms.Resize((224, 224)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "# )\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     dataset,\n",
    "#     batch_size=8,\n",
    "#     shuffle=True,\n",
    "#     num_workers=0\n",
    "# )\n",
    "\n",
    "# for image, label_classification in train_loader:\n",
    "#     print(label_classification)\n",
    "#     print(label_classification.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font size = 5 color = black>報錯修正</font>**\n",
    "\n",
    "<font color = blue>如果無法執行模型，並發現是報錯在loss.backward()的話\n",
    "<br>清除dataset(包含)資料夾內部的資料夾的ipynb_checkpoints\n",
    "<br>清除方式:\n",
    "<br><font color = red>du -chd 1 | sort -h 進行查詢</font>\n",
    "<br><font color = red>rm -rf .ipynb_checkpoints 進行清除</font>\n",
    "<br><font color = blue>驗證，觀察train_dataset, test_dataset的總和是否為正確數值</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1559 1038\n"
     ]
    }
   ],
   "source": [
    "test_percent = 0.4\n",
    "num_test = int(test_percent * len(dataset))\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [len(dataset) - num_test, num_test])\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color = blue size = 6> Test data label value</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#     train_dataset,\n",
    "#     batch_size=8,\n",
    "#     shuffle=True,\n",
    "#     num_workers=0\n",
    "# )\n",
    "\n",
    "\n",
    "# for image, label_regression, label_classification in train_loader:\n",
    "#     print(label_regression)\n",
    "#     print(label_classification.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super( MultiOutputModel, self).__init__()\n",
    "        self.out1 = torch.nn.Linear(512, 2)\n",
    "        self.out2 = torch.nn.Linear(512, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_out1 = self.out1(x)\n",
    "        x_out2 = self.out2(x) \n",
    "        return x_out1, x_out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = MultiOutputModel()\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.944123\n",
      "0.085708, 0.074738\n",
      "1: 0.922929\n",
      "0.037027, 0.043029\n",
      "2: 0.952794\n",
      "0.028049, 0.016599\n",
      "3: 0.917148\n",
      "0.028980, 0.022457\n",
      "4: 0.947013\n",
      "0.028723, 0.027793\n",
      "5: 0.962428\n",
      "0.025337, 0.017471\n",
      "6: 0.978805\n",
      "0.023086, 0.015762\n",
      "7: 0.950867\n",
      "0.021709, 0.042783\n",
      "8: 0.934489\n",
      "0.023076, 0.018545\n",
      "9: 0.976879\n",
      "0.025381, 0.026988\n",
      "10: 0.962428\n",
      "0.019109, 0.032352\n",
      "11: 0.947013\n",
      "0.023687, 0.014098\n",
      "12: 0.975915\n",
      "0.019173, 0.014188\n",
      "14: 0.949904\n",
      "0.017705, 0.040026\n",
      "15: 0.646435\n",
      "0.019961, 0.022742\n",
      "16: 0.958574\n",
      "0.017981, 0.009302\n",
      "17: 0.960501\n",
      "0.015579, 0.023712\n",
      "18: 0.963391\n",
      "0.016304, 0.011652\n",
      "19: 0.927746\n",
      "0.015963, 0.012250\n",
      "20: 0.973025\n",
      "0.013972, 0.015046\n",
      "21: 0.980732\n",
      "0.017071, 0.009916\n",
      "22: 0.976879\n",
      "0.015873, 0.019514\n",
      "23: 0.955684\n",
      "0.016683, 0.051465\n",
      "24: 0.981696\n",
      "0.016047, 0.011223\n",
      "25: 0.974952\n",
      "0.015974, 0.015946\n",
      "26: 0.968208\n",
      "0.015612, 0.010605\n",
      "27: 0.972062\n",
      "0.016558, 0.010027\n",
      "28: 0.978805\n",
      "0.012368, 0.014043\n",
      "29: 0.966281\n",
      "0.015327, 0.013070\n",
      "30: 0.980732\n",
      "0.017416, 0.019445\n",
      "31: 0.985549\n",
      "0.012466, 0.008906\n",
      "32: 0.973025\n",
      "0.011048, 0.008454\n",
      "33: 0.983622\n",
      "0.011908, 0.011984\n",
      "34: 0.971098\n",
      "0.011376, 0.028853\n",
      "35: 0.953757\n",
      "0.012385, 0.017202\n",
      "36: 0.958574\n",
      "0.015932, 0.010974\n",
      "37: 0.985549\n",
      "0.011199, 0.009763\n",
      "38: 0.949904\n",
      "0.012393, 0.012023\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-9e97d88784d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mloss_total\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time \n",
    "start = time.time()\n",
    "\n",
    "NUM_EPOCHS = 60\n",
    "# NUM_EPOCHS = 30\n",
    "BEST_MODEL_PATH = 'Merge_Function_Robot_final_v13.pth'\n",
    "best_loss = 1e9\n",
    "best_accuracy = 0.0\n",
    "\n",
    "#Regression & Classification\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for images, label_regression, label_classification in iter(train_loader):\n",
    "        images = images.to(device)\n",
    "  \n",
    "        label_regression = label_regression.to(device)  \n",
    "        label_classification = label_classification.long().to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        \n",
    "        output1, output2 = model(images)   \n",
    "        #Regression\n",
    "        loss1 = F.mse_loss(output1, label_regression)\n",
    "        #Classification\n",
    "        loss2 = F.cross_entropy(output2, label_classification)\n",
    "        \n",
    "        train_loss += float(loss1)     \n",
    "        loss_total = loss1 + loss2\n",
    "        loss_total.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "    train_loss /= len(train_loader)\n",
    "     \n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_error_count = 0.0\n",
    "    \n",
    "    for images, label_regression, label_classification in iter(test_loader):\n",
    "        images = images.to(device)\n",
    "        label_regression = label_regression.to(device) \n",
    "        label_classification = label_classification.long().to(device) \n",
    "        \n",
    "        output1, output2 = model(images)   \n",
    "        \n",
    "        # Regression\n",
    "        loss = F.mse_loss(output1, label_regression)\n",
    "        test_loss += float(loss)  \n",
    "        #Classification\n",
    "        test_error_count += float(torch.sum(torch.abs(label_classification - output2.argmax(1))))\n",
    "        \n",
    "    #Regression\n",
    "    test_loss /= len(test_loader)\n",
    "    #Classification\n",
    "    test_accuracy = 1.0 - float(test_error_count) / float(len(test_dataset))\n",
    "    \n",
    "    print('%d: %f' % (epoch, test_accuracy))\n",
    "    print('%f, %f' % (train_loss, test_loss))\n",
    "    \n",
    "    if (test_loss < best_loss) or (test_accuracy > best_accuracy):\n",
    "        torch.save(model.state_dict(), BEST_MODEL_PATH)\n",
    "        if (test_loss < best_loss):\n",
    "            best_loss = test_loss\n",
    "        if (test_accuracy > best_accuracy):\n",
    "            best_accuracy = test_accuracy\n",
    "end = time.time()\n",
    "print(\"finish\")    \n",
    "second = (end - start)\n",
    "\n",
    "minute = second // 60\n",
    "hour = second // 60 //60\n",
    "second = second % 60 % 60\n",
    "print('this model training spends %0dhr %0dmin %0ds' % (hour, minute, second))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
